import os
import cv2
import comfy
import torch
import numpy as np  # ç¡®ä¿å·²å®‰è£…
import folder_paths
from tqdm import tqdm

class VideoToFramesNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video_path": ("STRING", {"default": "", "multiline": False}),
                "output_dir": ("STRING", {"default": "output/video_frames", "multiline": False}),
                "filename_prefix": ("STRING", {"default": "frame"}),
                "format": (["jpg", "png", "webp"], {"default": "jpg"}),
            },
        }

    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("output_info", "images")
    FUNCTION = "convert_video"
    CATEGORY = "ğŸ¨å…¬ä¼—å·æ‡‚AIçš„æœ¨å­åšå·å·¥å…·/æ‡’äººåšå·/è§†é¢‘ç›¸å…³"
    OUTPUT_NODE = True

    def convert_video(self, video_path, output_dir, filename_prefix, format):
        # æ ¡éªŒè¾“å…¥æ–‡ä»¶
        if not os.path.isfile(video_path):
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        
        # å¤„ç†å¸§æ•°æ®
        success, image = cap.read()
        count = 0
        images = []
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=total_frames, desc="Processing video frames")
        
        while success:
            # æ„é€ è¾“å‡ºè·¯å¾„
            frame_number = str(count).zfill(6)
            output_path = os.path.join(
                output_dir, 
                f"{filename_prefix}_{frame_number}.{format}"
            )
            
            # ä¿å­˜å›¾åƒ
            if format == "jpg":
                cv2.imwrite(output_path, image, [int(cv2.IMWRITE_JPEG_QUALITY), 95])
            elif format == "webp":
                cv2.imwrite(output_path, image, [int(cv2.IMWRITE_WEBP_QUALITY), 95])
            else:
                cv2.imwrite(output_path, image)
            
            # è½¬æ¢ä¸ºComfyUIå›¾åƒæ ¼å¼ (RGB 0-1)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image_norm = image_rgb.astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_norm)
            images.append(image_tensor)
            
            count += 1
            success, image = cap.read()
            pbar.update(1)
        
        cap.release()
        pbar.close()
        
        # å †å æ‰€æœ‰å¸§ä¸ºå¼ é‡ [N H W C]
        if len(images) > 0:
            images_tensor = torch.stack(images, dim=0)
        else:
            images_tensor = torch.zeros((0, 1, 1, 3))  # ç©ºå¼ é‡
            
        return (f"æˆåŠŸè½¬æ¢ {count} å¸§åˆ° {output_dir}", images_tensor)

NODE_CLASS_MAPPINGS = {
    "VideoToFramesNode": VideoToFramesNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoToFramesNode": "ğŸ“ºè§†é¢‘è½¬å›¾ç‰‡åºåˆ—"
}